{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge-guided ML for Dynamical Systems\n",
    "\n",
    "This part of the homework focuses on knowledge-guided machine learning (KGML) methods for modeling dynamical systems. You will implement simplified versions of Neural ODE (NODE), Hamiltonian Neural Network (HNN), and Symplectic ODE-Net (SymODEN), which are methods we discussed in class. The last two methods blend physical knowledge with neural networks to enhance model interpretability and generalizability when modeling systems with inherent physical properties (like conservation of energy).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Neural ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following libraries will be necessary for your implementation. Ensure you have them installed before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.integrate # SciPy module for integrating ODEs\n",
    "solve_ivp = scipy.integrate.solve_ivp\n",
    "from torchdiffeq import odeint  # Solver for ODEs integrated with PyTorch\n",
    "\n",
    "# Custom functions and datasets for the pendulum problem\n",
    "from data_pend import get_dataset, get_field, get_trajectory, dynamics_fn, hamiltonian_fn\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed = 888\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Plotting parameters\n",
    "LINE_SEGMENTS = 10\n",
    "ARROW_SCALE = 40\n",
    "ARROW_WIDTH = 6e-3\n",
    "LINE_WIDTH = 2\n",
    "DPI = 300\n",
    "R = 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "You will load the numerical solution of the ideal pendulum equations for Hamiltonian $$H(q, p) = 1.5 p^2 + 5(1-cos q).$$\n",
    "\n",
    "Here your inverse mass is $3$ and potential energy $V (q) = 5(1 - cos q).$ As depicted in the figure below, $q$ is angular position, and $p$ is momentum. \n",
    "\n",
    "Your models will be trained with the synthetic data generated based on this Hamilonian. The data consists of training and test sets of 25 trajectories each and added Gaussian noise with standard deviation $\\sigma^2 = 0.1$ to every data point. Each trajectory has 30 observations; each observation is a concatenation of $(q,p)$. Note that for our methods we assume we do not know the exact Hamiltonian equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function to generate data\n",
    "data = get_dataset(seed=seed)\n",
    "# Convert data to PyTorch tensors\n",
    "x = torch.tensor( data['x'], dtype=torch.float32)\n",
    "test_x = torch.tensor( data['test_x'], dtype=torch.float32)\n",
    "dx_dt = torch.Tensor(data['dx'])\n",
    "test_dx_dt = torch.Tensor(data['test_dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "field = get_field(xmin=-R, xmax=R, ymin=-R, ymax=R, gridsize=15)\n",
    "\n",
    "###### PLOT ######\n",
    "fig = plt.figure(figsize=(8, 2.6), facecolor='white', dpi=DPI)\n",
    "\n",
    "# plot physical system\n",
    "fig.add_subplot(1, 4, 1, frameon=True) \n",
    "plt.xticks([]) ;  plt.yticks([])\n",
    "schema = mpimg.imread('pendulum.png')\n",
    "plt.imshow(schema)\n",
    "plt.title(\"Pendulum system\", pad=10)\n",
    "\n",
    "# plot one single trajectory, for a given initial conditions\n",
    "y0 = np.asarray([2.1, 0])\n",
    "fig.add_subplot(1, 4, 2, frameon=True)\n",
    "x_traj, y_traj, dx_traj, dy_traj, t_traj = get_trajectory(t_span=[0,4], radius=2.1, y0=y0)\n",
    "N = len(x_traj)\n",
    "point_colors = [(i/N, 0, 1-i/N) for i in range(N)]\n",
    "plt.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "           cmap='gray_r', color=(.5,.5,.5))\n",
    "plt.scatter(x_traj, y_traj, s=14, label='data', c=point_colors)\n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"One trajectory\", pad=10)\n",
    "\n",
    "# plot all trajectory (training data), each trajectory a different initial condition\n",
    "fig.add_subplot(1, 4, 3, frameon=True)\n",
    "plt.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "           cmap='gray_r', color=(.5,.5,.5))\n",
    "plt.scatter(data['x'][:,0],data['x'][:,1],s=10, c='b',alpha=0.3)\n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"Many trajectories \\n(our training data)\", pad=10)\n",
    "\n",
    "plt.tight_layout() ; plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural ODE architecture\n",
    "\n",
    "A basic architecture for your Neural ODE is provided. \n",
    "\n",
    "**Task 1: Complete the integrate method**\n",
    "* Use the function `odeint` from `torchdiffeq`.\n",
    "* Input `x0` are your initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(nn.Module):\n",
    "    ''' NeuralODE on canonical coordinates'''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, output_dim, bias=None)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights(self.net)\n",
    "\n",
    "    def _initialize_weights(self, module):\n",
    "        # Xavier (Glorot) initialization for all linear layers\n",
    "        for layer in module:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)  # Initialize weights\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)  # Initialize biases to zero\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        '''Compute the time derivative of x, dx/dt, using the neural network'''\n",
    "        dx_dt = self.net(x)\n",
    "        return dx_dt\n",
    "    \n",
    "    def simulate(self, x0, t):\n",
    "        '''\n",
    "        Simulate the system dynamics over time using the neural network output.\n",
    "        - x0: Initial state of the system\n",
    "        - t: Time points for simulation\n",
    "        '''\n",
    "        # TODO: Integrate using output of the neural network, use method dopri5\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: Instantiate the Neural ODE Model**\n",
    "* Define the dimensions (input_dim, hidden_dim, output_dim) for the network and instantiate the NODE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate the model\n",
    "node_model = NeuralODE(\n",
    "    input_dim=...,  \n",
    "    hidden_dim=..., \n",
    "    output_dim=..., \n",
    ")\n",
    "\n",
    "# Display the neural network architecture\n",
    "print(node_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural ODE \n",
    "\n",
    "**Task 3: Forward pass and loss computation**\n",
    "* For both train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \"\"\" Function to train our neural dynamical models \"\"\"\n",
    "    # Set up the optimizer\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    # Set maximum training iterations and print frequency for logging\n",
    "    max_iterations = 2000\n",
    "    print_every = 100\n",
    "    # Loss\n",
    "    loss_fcn = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    for iteration in range(max_iterations+1):\n",
    "        \n",
    "        # TODO: Perform a forward pass on the training data and compute the loss\n",
    "        # dx_dt_hat is the predicted time derivatives (model output)\n",
    "        dx_dt_hat = ...\n",
    "        loss = loss_fcn(...)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        if iteration % print_every == 0:\n",
    "            # TODO: Same as before, now use test data\n",
    "            test_dx_dt_hat = ...\n",
    "            test_loss = loss_fcn(...)\n",
    "            # logging\n",
    "            print(\"iteration {}, train_loss {:.4e}, test_loss {:.4e}\".format(iteration, loss.item(), test_loss.item()))\n",
    "\n",
    "train_model(node_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Hamilonian Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamilonian Neural Architecture\n",
    "\n",
    "A basic architecture for the HNN is provided. \n",
    "\n",
    "**Task 4: Compute derivatives based on Hamiltonian**\n",
    "* Leverage the properties of the Hamiltonian formalism\n",
    "\n",
    "**Task 5: Construct dx_dt**\n",
    "* Put together the two derivatives for your canonical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamiltonianNN(NeuralODE):\n",
    "    ''' Hamiltonian neural net on canonical coordinates\n",
    "        This class extends the NeuralODE class and incorporates the Hamiltonian formalism.\n",
    "\n",
    "        It predicts the system's Hamiltonian and uses its gradient to compute \n",
    "        time derivatives of the system's canonical coordinates (position and momentum).\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 input_dim, hidden_dim, output_dim):\n",
    "        super().__init__(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    def hamiltonian(self, x):\n",
    "        # Compute the Hamiltonian of the system using the neural network.\n",
    "        H = self.net(x)\n",
    "        return H\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        Compute the time derivative of the input state using the Hamiltonian formulation\n",
    "        It returns the time derivative of the input state, containing dq/dt and dp/dt.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Reshape input to ensure it is of shape (-1, 2) for pairs of (q, p)\n",
    "        x = x.reshape(-1,2)\n",
    "\n",
    "        # Enable gradient tracking for the input tensor to compute derivatives\n",
    "        x = x.requires_grad_(True)\n",
    "\n",
    "        # TODO: Predict the Hamiltonian for the current state\n",
    "        H = ...\n",
    "\n",
    "        # TODO: Compute the gradient of the Hamiltonian with respect to input coordinates\n",
    "        dH_dx = ...\n",
    "\n",
    "        # Reshape gradient to match the expected dimensions\n",
    "        dH_dx = dH_dx.reshape(-1,2)\n",
    "        \n",
    "        # TODO: Compute time derivatives using the Hamiltonian gradients\n",
    "        dq_dt = ...\n",
    "        dp_dt = ...\n",
    "\n",
    "        # TODO: Put them together\n",
    "        dx_dt = ...\n",
    "        \n",
    "        # Make sure they are the same shape as input x\n",
    "        dx_dt = dx_dt.reshape_as(x)\n",
    "\n",
    "        return dx_dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6: Instantiate the HNN Model**\n",
    "* Define the dimensions (input_dim, hidden_dim, output_dim) for the network and instantiate the HNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate the HNN model\n",
    "hnn_model = HamiltonianNN(\n",
    "    input_dim=...,  \n",
    "    hidden_dim=..., \n",
    "    output_dim=..., \n",
    ")\n",
    "print(hnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_model(hnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the solution\n",
    "\n",
    "Run the code below to visualize the fields learned by the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_field(model, **kwargs):\n",
    "    field = get_field(**kwargs)\n",
    "    np_mesh_x = field['x']\n",
    "    # run model\n",
    "    mesh_x = torch.tensor(np_mesh_x, requires_grad=True, dtype=torch.float32)\n",
    "    mesh_dx = model.forward(None, mesh_x)\n",
    "    return mesh_dx.data.numpy()\n",
    "\n",
    "def energy_loss(true_x, integrated_x):\n",
    "    true_energy = (true_x**2).sum(1)\n",
    "    integration_energy = (integrated_x**2).sum(1)\n",
    "    return np.mean((true_energy - integration_energy)**2)\n",
    "\n",
    "# get their vector fields\n",
    "R = 2.6\n",
    "field = get_field(xmin=-R, xmax=R, ymin=-R, ymax=R, gridsize=10)\n",
    "data = get_dataset(radius=2.0)\n",
    "node_field = get_vector_field(node_model, xmin=-R, xmax=R, ymin=-R, ymax=R, gridsize=10)\n",
    "hnn_field = get_vector_field(hnn_model, xmin=-R, xmax=R, ymin=-R, ymax=R, gridsize=10)\n",
    "\n",
    "# integrate along those fields starting from point (1,0)\n",
    "t_span = torch.linspace(0, 28, 1000, dtype=torch.float32)\n",
    "x0 = torch.tensor([2.1, 0], dtype=torch.float32)\n",
    "node_ivp = node_model.simulate(x0, t_span)\n",
    "hnn_ivp = hnn_model.simulate(x0, t_span)\n",
    "\n",
    "\n",
    "###### PLOT ######\n",
    "fig = plt.figure(figsize=(11.3, 3.2), facecolor='white', dpi=DPI)\n",
    "\n",
    "# plot physical system\n",
    "fig.add_subplot(1, 4, 1, frameon=True) \n",
    "plt.xticks([]) ;  plt.yticks([])\n",
    "schema = mpimg.imread('pendulum.png')\n",
    "plt.imshow(schema)\n",
    "plt.title(\"Pendulum system\", pad=10)\n",
    "\n",
    "# plot dynamics\n",
    "fig.add_subplot(1, 4, 2, frameon=True)\n",
    "x_traj, y_traj, dx_traj, dy_traj, t_traj = get_trajectory(t_span=[0,4], radius=2.1, y0=x0.detach().numpy())\n",
    "N = len(x_traj)\n",
    "point_colors = [(i/N, 0, 1-i/N) for i in range(N)]\n",
    "plt.scatter(x_traj, y_traj, s=14, label='data', c=point_colors)\n",
    "\n",
    "plt.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "        cmap='gray_r', scale=ARROW_SCALE, width=ARROW_WIDTH, color=(.2,.2,.2))  \n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"Data\", pad=10)\n",
    "\n",
    "# plot neural ODE\n",
    "fig.add_subplot(1, 4, 3, frameon=True)\n",
    "plt.quiver(field['x'][:,0], field['x'][:,1], node_field[:,0], node_field[:,1],\n",
    "        cmap='gray_r', scale=ARROW_SCALE, width=ARROW_WIDTH, color=(.2,.2,.2))\n",
    "\n",
    "for i, l in enumerate(np.split(node_ivp.detach().numpy(), LINE_SEGMENTS)):\n",
    "    color = (float(i)/LINE_SEGMENTS, 0, 1-float(i)/LINE_SEGMENTS)\n",
    "    plt.plot(l[:,0],l[:,1],color=color, linewidth=LINE_WIDTH)\n",
    "    \n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"Neural ODE\", pad=10)\n",
    "\n",
    "# plot HNN\n",
    "fig.add_subplot(1, 4, 4, frameon=True)\n",
    "plt.quiver(field['x'][:,0], field['x'][:,1], hnn_field[:,0], hnn_field[:,1],\n",
    "        cmap='gray_r', scale=ARROW_SCALE, width=ARROW_WIDTH, color=(.2,.2,.2))\n",
    "\n",
    "for i, l in enumerate(np.split(hnn_ivp.detach().numpy(), LINE_SEGMENTS)):\n",
    "    color = (float(i)/LINE_SEGMENTS, 0, 1-float(i)/LINE_SEGMENTS)\n",
    "    plt.plot(l[:,0],l[:,1],color=color, linewidth=LINE_WIDTH)\n",
    "\n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"Hamiltonian NN\", pad=10)\n",
    "\n",
    "plt.tight_layout() ; plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s examine the error over time and the total energy. Recall that in our ideal pendulum system, there is no energy loss, so our goal is to learn dynamics that accurately conserve energy throughout the motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_models(dynamics_fn, model, x0, t_span, t_eval):\n",
    "    kwargs = {'t_eval': t_eval, 'rtol': 1e-12}\n",
    "    true_path = solve_ivp(fun=dynamics_fn, t_span=t_span, y0=x0, **kwargs)\n",
    "    true_x = true_path['y'].T\n",
    "\n",
    "    t_span_tensor = torch.tensor(t_eval, dtype=torch.float32)\n",
    "    x0_tensor = torch.tensor(x0, dtype=torch.float32)\n",
    "    model_x = model.simulate(x0_tensor, t_span_tensor).detach().numpy()\n",
    "\n",
    "    return true_x, model_x\n",
    "\n",
    "def evaluate_models(x0, t_span, model1, model1_name, model2, model2_name, dynamics_fn, hamiltonian_fn):\n",
    "\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], 2000)\n",
    "\n",
    "    # Integrate the models\n",
    "    true_x, model1_x = integrate_models(dynamics_fn, model1, x0, t_span, t_eval)\n",
    "    _, model2_x = integrate_models(dynamics_fn, model2, x0, t_span, t_eval)\n",
    "\n",
    "    # Plotting\n",
    "    tpad = 7\n",
    "    fig = plt.figure(figsize=[9, 3], dpi=100)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Predictions\", pad=tpad)\n",
    "    plt.xlabel('$q$')\n",
    "    plt.ylabel('$p$')\n",
    "    plt.plot(true_x[:, 0], true_x[:, 1], 'k-', label='Ground truth', linewidth=2)\n",
    "    plt.plot(model1_x[:, 0], model1_x[:, 1], 'r-', label=model1_name, linewidth=2)\n",
    "    plt.plot(model2_x[:, 0], model2_x[:, 1], 'b-', label=model2_name, linewidth=2)\n",
    "    plt.xlim(-2.5, 4)\n",
    "    plt.ylim(-2.5, 4)\n",
    "    plt.legend(fontsize=7)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"MSE between coordinates\", pad=tpad)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.plot(t_eval, ((true_x - model1_x) ** 2).mean(-1), 'r-', label=model1_name, linewidth=2)\n",
    "    plt.plot(t_eval, ((true_x - model2_x) ** 2).mean(-1), 'b-', label=model2_name, linewidth=2)\n",
    "    plt.legend(fontsize=7)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Total energy\", pad=tpad)\n",
    "    plt.xlabel('Time step')\n",
    "    true_e = np.stack([hamiltonian_fn(c) for c in true_x])\n",
    "    model1_e = np.stack([hamiltonian_fn(c) for c in model1_x])\n",
    "    model2_e = np.stack([hamiltonian_fn(c) for c in model2_x])\n",
    "    plt.plot(t_eval, true_e, 'k-', label='Ground truth', linewidth=2)\n",
    "    plt.plot(t_eval, model1_e, 'r-', label=model1_name, linewidth=2)\n",
    "    plt.plot(t_eval, model2_e, 'b-', label=model2_name, linewidth=2)\n",
    "    plt.legend(fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "x0 = np.asarray([2.1, 0])\n",
    "t_span = [0, 20]\n",
    "evaluate_models(x0, t_span, node_model, 'Neural ODE', hnn_model, 'Hamiltonian NN', dynamics_fn, hamiltonian_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Symplectic ODE-Net (SymODEN) \n",
    "\n",
    "SymODEN, unlike Hamiltonian Neural Networks (HNNs), explicitly utilizes a Hamiltonian formulation that accounts for both position and potential energy in the system. While our earlier methods did not leverage system parameters such as mass, we will continue to assume that this information is unavailable. However, we will exploit the fact that, in canonical coordinates, the Hamiltonian follows the general form:\n",
    "$$H_{\\theta_1, \\theta_2}(\\mathbf{q}, \\mathbf{p}) = \\frac{1}{2} \\mathbf{p}^T \\mathbf{M}_{\\theta_1}^{-1}(\\mathbf{q}) \\mathbf{p} + V_{\\theta_2}(\\mathbf{q}),$$\n",
    "where  \\mathbf{q}  and  \\mathbf{p}  represent position and momentum, respectively. In your implementation of SymODEN, you will build two neural networks: one to predict the inverse mass matrix $\\mathbf{M}_{\\theta_1}^{-1}(\\mathbf{q})$ and another to predict the potential energy $V_{\\theta_2}(\\mathbf{q})$. This approach allows the model to capture the underlying structure of the physical system without explicitly knowing the system’s parameters, improving both interpretability and generalization.\n",
    "\n",
    "**Task 7: Compute the Hamiltonian**\n",
    "* Use your two neural networks and the equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymODEN(HamiltonianNN):\n",
    "    ''' \n",
    "    Symplectic ODE-Net (SymODEN)\n",
    "\n",
    "    This class extends HamiltonianNN by introducing two neural networks to predict \n",
    "    the inverse mass matrix and potential energy. It leverages the \n",
    "    symplectic structure of physical systems to accurately capture the system dynamics \n",
    "    without direct knowledge of parameters like mass. \n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 input_dim, hidden_dim, output_dim):\n",
    "        super().__init__(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "        # Neural network to predict the inverse mass matrix M^{-1}(q)\n",
    "        self.M_net = nn.Sequential(\n",
    "            nn.Linear(input_dim//2, hidden_dim//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim//2, output_dim, bias=None)\n",
    "        )\n",
    "\n",
    "        # Neural network to predict the potential energy V(q)\n",
    "        self.V_net = nn.Sequential(\n",
    "            nn.Linear(input_dim//2, hidden_dim//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim//2, output_dim, bias=None)\n",
    "        )\n",
    "\n",
    "        # Set the net attribute to None since SymODEN uses two separate networks\n",
    "        self.net = None\n",
    "\n",
    "        # Initialize the weights of both neural networks\n",
    "        self._initialize_weights(self.M_net)\n",
    "        self._initialize_weights(self.V_net)\n",
    "\n",
    "    def hamiltonian(self, x):\n",
    "        # Split the input tensor into position (q) and momentum (p)\n",
    "        q, p = torch.chunk(x, 2, dim=1)\n",
    "        \n",
    "        # TODO: Compute the Hamiltonian using your two neural networks\n",
    "        V_q = ...\n",
    "        M_q_inv = ...\n",
    "        H = ...\n",
    "        return H\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8: Instantiate the Model**\n",
    "* Define the dimensions (input_dim, hidden_dim, output_dim) for the network and instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate the model\n",
    "symODE_model = SymODEN(\n",
    "    input_dim=...,  \n",
    "    hidden_dim=..., \n",
    "    output_dim=..., \n",
    ")\n",
    "print(symODE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_model(symODE_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare this new model with the HNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.asarray([2.1, 0])\n",
    "t_span = [0, 20]\n",
    "evaluate_models(x0, t_span, hnn_model, 'Hamiltonian NN', symODE_model, 'SymODEN', dynamics_fn, hamiltonian_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Learned Functions for Inverse Mass and Potential Energy\n",
    "\n",
    "Even if the total energy closely matches the ground truth, you may observe a non-trivial discrepancy (bias) between the predicted and true potential energy. This difference highlights subtle challenges in accurately learning individual components of the energy function. For a detailed explanation of this phenomenon, refer to the SymODEN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 2.5), dpi=DPI)\n",
    "q = np.linspace(-R, R, 40)\n",
    "q_tensor = torch.tensor(q, dtype=torch.float32).view(40, 1)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "M_q_inv = symODE_model.M_net(q_tensor)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(q, 3 * np.ones_like(q), label='Ground Truth', color='k', linewidth=2)\n",
    "plt.plot(q, M_q_inv.detach().cpu().numpy(), 'b--', linewidth=3, label=r'SymODEN $M^{-1}_{\\theta_1}(q)$')\n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.title(\"$M^{-1}(q)$\", pad=10, fontsize=14)\n",
    "plt.xlim(-R, R)\n",
    "plt.ylim(0, 4)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "V_q = symODE_model.V_net(q_tensor)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(q, 5*(1-np.cos(q)), label='Ground Truth', color='k', linewidth=2)\n",
    "plt.plot(q, V_q.detach().cpu().numpy(), 'b--', linewidth=3, label=r'SymODEN $V_{\\theta_2}(q)$')\n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.title(\"$V(q)$\", pad=10, fontsize=14)\n",
    "plt.xlim(-R, R)\n",
    "plt.ylim(-15, 20)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 9: Comment on the results**\n",
    "* Compare methods quantitatively and qualitatively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse598",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
