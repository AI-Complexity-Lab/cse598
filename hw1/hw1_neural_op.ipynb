{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f849d467-b2a6-4efa-827b-f93b6a9f6053",
   "metadata": {},
   "source": [
    "# Part 1: Fourier Neural Operator (FNO)\n",
    "\n",
    "The following libraries will be necessary for your implementation. Ensure you have them installed before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9162981-7ee2-427f-8356-35733c066e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Union\n",
    "from neuralop import Trainer\n",
    "from neuralop.data.datasets.darcy import load_darcy_flow_small\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from spectral_convolution import SpectralConvolution\n",
    "from mlp import MLP\n",
    "\n",
    "# PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf6b1e-e980-4df5-b743-f392cf5f9d1d",
   "metadata": {},
   "source": [
    "### Building the FNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce589a9-c00c-45b3-bb26-0ea13b64dd6e",
   "metadata": {},
   "source": [
    "We will implement the Fourier Neural Operator (FNO) class, an advanced neural network model used for solving Partial Differential Equations (PDEs) through deep learning. The FNO utilizes Fourier transformations to learn global representations and can be particularly effective for high-dimensional data.\n",
    "\n",
    "Let's start with the Fourier block which you will implement using the modules `SpectralConvolution` and `MLP`. You are given the constructor and you will have to work on the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394411b-0a16-43a4-b719-f594f4a9a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Fourier block used in the Fourier Neural Operator (FNO).\n",
    "    Combines spectral convolution, MLP, and convolution layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, modes: Union[List[int], int], in_channels: int, out_channels: int, \n",
    "                 hidden_size: int, activation: nn.Module = nn.GELU()) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize the spectral convolution (Fourier layer)\n",
    "        self.fourier = SpectralConvolution(in_channels, out_channels, modes)\n",
    "\n",
    "        # MLP layer (which will do a linear transformation of the input)\n",
    "        self.mlp = MLP(len(modes), in_channels, out_channels, hidden_size, activation)\n",
    "\n",
    "        # Initialize the 2D convolution layer with kernel size of 3 and padding of 1\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "\n",
    "        # Activation function for the block\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the FourierBlock.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Input tensor of shape [batch, channels, *sizes]\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        x: torch.Tensor\n",
    "            Output tensor of shape [batch, channels, *sizes]\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO - Apply spectral convolution to input tensor\n",
    "        x_ft = ...\n",
    "\n",
    "        # TODO - Apply 2D convolution to input tensor\n",
    "        x_conv = ...\n",
    "\n",
    "        # Add the Fourier and convolution outputs\n",
    "        x = x_ft + x_conv\n",
    "\n",
    "        # TODO - Apply MLP to the result\n",
    "        x_mlp = ...\n",
    "        x = ...\n",
    "\n",
    "        # TODO - Apply activation function to the final result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143d2a9",
   "metadata": {},
   "source": [
    "\n",
    "Below is the skeleton of the `FNO` class. Certain parts are intentionally left blank for you to complete - **marked TODO for code you need to complete**. Follow the comments to understand what each part should accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d46296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO(nn.Module):\n",
    "    \"\"\"\n",
    "    Fourier Neural Operator (FNO) for solving PDEs.\n",
    "    \"\"\"\n",
    "    def __init__(self, modes: List[int], num_fourier_layers: int, in_channels: int, \n",
    "                 lifting_channels: int, projection_channels: int, out_channels: int, \n",
    "                 hidden_channels: int, activation: nn.Module):\n",
    "        super().__init__()\n",
    "        self.dim = len(modes)\n",
    "        self.activation = activation\n",
    "\n",
    "        # Lifting layer \n",
    "        self.lifting = MLP(2, in_channels, hidden_channels, lifting_channels)\n",
    "        \n",
    "        # TODO - Initialize a list of FourierBlock modules with modes, hidden_channels, hidden_size and activation as parameters.\n",
    "        #        You are free to choose which hidden_size is best for the model\n",
    "        self.fourier_blocks = nn.ModuleList([\n",
    "            ...\n",
    "        ])\n",
    "        \n",
    "        # TODO - Use projection layers\n",
    "        self.q1 = ...\n",
    "        self.final = ...\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        # TODO - Implement lifting layer\n",
    "        x = ...\n",
    "        \n",
    "        # TODO - Pass the input through each FourierBlock sequentially\n",
    "        for fourier_block in self.fourier_blocks:\n",
    "            x = ...\n",
    "\n",
    "        # Permute the dimensions back to [batch, sizes, channels].\n",
    "        x = x.permute(0, *range(2, self.dim + 2), 1)\n",
    "\n",
    "        # TODO - Apply projection and final layer\n",
    "        x = ...\n",
    "        x = ...\n",
    "        x = ...\n",
    "        \n",
    "        # Permute to [batch, channels, sizes] format for output and return.\n",
    "        return x.permute(0, -1, *range(1, self.dim + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c2aa9-35c2-4b93-a03c-c8f56b472c84",
   "metadata": {},
   "source": [
    "### Training the Fourier Neural Operator on Darcy Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811a9a6-6fa0-499f-ab69-84ac7baa271e",
   "metadata": {},
   "source": [
    "In this example, we demonstrate how to use the small Darcy-Flow example we ship with the package \"neuralop\" to train a Tensorized Fourier-Neural Operator.\n",
    "\n",
    "*There is no code to fill in for this part, just run the code block by block in order.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451222b2-459c-48d1-9a1b-07dedc5cd408",
   "metadata": {},
   "source": [
    "**Loading the Navier-Stokes dataset in 128x128 resolution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd849f5-28bb-4e55-a42f-405e7e197ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 16 with 100 samples \n",
      "Loading test db for resolution 32 with 50 samples \n"
     ]
    }
   ],
   "source": [
    "# Load Darcy flow dataset\n",
    "train_loader, test_loaders, data_processor = load_darcy_flow_small(\n",
    "    n_train=1000, batch_size=32, test_resolutions=[16, 32], n_tests=[100, 50],\n",
    "    test_batch_sizes=[32, 32], positional_encoding=True\n",
    ")\n",
    "data_processor = data_processor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083b5ee-807b-4045-85b9-533eb1845e71",
   "metadata": {},
   "source": [
    "Let's create an instance of our FNO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910b855-f1cf-4967-8011-792bff9832c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "# TODO - Tune hyperparameters of FNO; \n",
    "# hint: use small values for channels and no more than 6 layers\n",
    "model = FNO(modes=[16, 16], num_fourier_layers=..., in_channels=3,\n",
    "            lifting_channels=..., hidden_channels=..., projection_channels=...,\n",
    "            out_channels=1, activation=nn.GELU())\n",
    "model = model.to(device)\n",
    "\n",
    "# Count model parameters\n",
    "n_params = count_model_params(model)\n",
    "print(f'\\nModel parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dce77-2e1b-469f-bc2e-3651db5e7135",
   "metadata": {},
   "source": [
    "Here's a quick visualization of the input and ground truth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00124c89-f2cb-4ff3-8123-6625ce7331b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can change the resolution from 16 to 32 to see the resolution difference if you'd like.\n",
    "#Note: Because DeepONet trains and tests on same resolution, and our Darcy Flow dataset only contains training\n",
    "# data of resolution 16, testing with 16 here is recommended for a better comparison (in DeepONet section of this HW).\n",
    "test_samples = test_loaders[16].dataset\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "for index in range(3):\n",
    "    data = test_samples[index]\n",
    "    data = data_processor.preprocess(data, batched=False)\n",
    "    # Input x\n",
    "    x = data['x']\n",
    "    # Ground-truth\n",
    "    y = data['y']\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
    "    ax.imshow(x[0], cmap='gray')\n",
    "    if index == 0:\n",
    "        ax.set_title('Input x')   \n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
    "    ax.imshow(y.squeeze())\n",
    "    if index == 0:\n",
    "        ax.set_title('Ground-truth y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71605fb1-5b58-4942-b132-b0e7a8a7179b",
   "metadata": {},
   "source": [
    "Create the optimizer and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cfae67-0fef-49bb-8139-4ce20aa17bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "train_loss = h1loss\n",
    "eval_losses = {'h1': h1loss, 'l2': l2loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec744f1a-39f5-40dc-b139-d10c035f535a",
   "metadata": {},
   "source": [
    "Visualize created instances for model and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b88c3-481d-4572-a1f2-14cbe8d61577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n### MODEL ###\\n', model)\n",
    "print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "print('\\n### LOSSES ###')\n",
    "print(f'\\n * Train: {train_loss}')\n",
    "print(f'\\n * Test: {eval_losses}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b39c0-ebab-4e47-a281-26e737acc0f3",
   "metadata": {},
   "source": [
    "Train the model using the trainer. For 20 epochs, it should take a few minutes only.\n",
    "\n",
    "Aim for your `16_l2` metric (L2 loss in 16x16 resolution images) to be less than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d11fb7-29f4-4d9c-bf01-fd0b322dbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = Trainer(model=model, n_epochs=20, device=device, data_processor=data_processor,\n",
    "                 use_distributed=False, verbose=True)\n",
    "trainer.train(train_loader=train_loader, test_loaders=test_loaders,\n",
    "              optimizer=optimizer, scheduler=scheduler, \n",
    "              regularizer=False, training_loss=train_loss, eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18527467-6f5e-48ce-b711-378daafd025b",
   "metadata": {},
   "source": [
    "### Plot the prediction, and compare with the ground-truth\n",
    "\n",
    "*Note:*\n",
    "- *We trained on a very small resolution for a very small number of epochs. In practice, we would train at larger resolution, on many more samples.*\n",
    "- *However, for practicity, we created a minimal example that*\n",
    "  - *fits in just a few Mb of memory*\n",
    "  - *can be trained quickly on CPU*\n",
    "\n",
    "*In practice we would train a Neural Operator on one or multiple GPUs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509f74f-2a53-43de-8707-a3ccb03dc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of predictions\n",
    "test_samples = test_loaders[32].dataset\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "for index in range(3):\n",
    "    data = test_samples[index]\n",
    "    data = data_processor.preprocess(data, batched=False)\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    out = model(x.unsqueeze(0))\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
    "    ax.imshow(x[0], cmap='gray')\n",
    "    if index == 0:\n",
    "        ax.set_title('Input x')\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
    "    ax.imshow(y.squeeze())\n",
    "    if index == 0:\n",
    "        ax.set_title('Ground-truth y')\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 3)\n",
    "    ax.imshow(out.squeeze().detach().numpy())\n",
    "    if index == 0:\n",
    "        ax.set_title('Model prediction')\n",
    "\n",
    "fig.suptitle('Inputs, Ground-truth, and Model Prediction')\n",
    "plt.tight_layout()\n",
    "plt.savefig('neural_ops_output.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106f8d3-1f1e-462d-ad11-e72a96d521e4",
   "metadata": {},
   "source": [
    "# Part 2: DeepONets\n",
    "\n",
    "In this section, you will implement the DeepONet class, another advanced neural network model used for solving Partial Differential Equations (PDEs) through deep learning. The trunk and branch method in DeepONet allows for the separation of input functions and locations, enabling efficient and flexible learning of nonlinear operators by independently processing the function space and input space.\n",
    "\n",
    "Below is the skeleton of the `DeepONet` class. Certain parts are intentionally left blank for you to complete - **marked TODO for code you need to complete**. Follow the comments to understand what each part should accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "381559c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DDE_BACKEND\"] = \"pytorch\"\n",
    "import deepxde as dde\n",
    "from deepxde.nn import FNN\n",
    "from deepxde.nn import NN\n",
    "from deepxde.nn import activations\n",
    "from deepxde.nn.pytorch.deeponet import (\n",
    "    SingleOutputStrategy,\n",
    "    IndependentStrategy,\n",
    "    SplitBothStrategy,\n",
    "    SplitBranchStrategy,\n",
    "    SplitTrunkStrategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178dd26-7bb4-4b79-89bc-ae0bdc64eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(NN):\n",
    "    \"\"\"Deep operator network.\n",
    "\n",
    "    `Lu et al. Learning nonlinear operators via DeepONet based on the universal\n",
    "    approximation theorem of operators. Nat Mach Intell, 2021.\n",
    "    <https://doi.org/10.1038/s42256-021-00302-5>`_\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes_branch,\n",
    "        layer_sizes_trunk,\n",
    "        activation,\n",
    "        kernel_initializer,\n",
    "        num_outputs=1,\n",
    "        multi_output_strategy=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Define activation functions for the branch and trunk networks\n",
    "        if isinstance(activation, dict):\n",
    "            self.activation_branch = activation[\"branch\"]\n",
    "            self.activation_trunk = activations.get(activation[\"trunk\"])\n",
    "        else:\n",
    "            self.activation_branch = self.activation_trunk = activations.get(activation)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "\n",
    "        self.num_outputs = num_outputs\n",
    "        if self.num_outputs == 1:\n",
    "            if multi_output_strategy is not None:\n",
    "                raise ValueError(\n",
    "                    \"num_outputs is set to 1, but multi_output_strategy is not None.\"\n",
    "                )\n",
    "        elif multi_output_strategy is None:\n",
    "            multi_output_strategy = \"independent\"\n",
    "            print(\n",
    "                f\"Warning: There are {num_outputs} outputs, but no multi_output_strategy selected. \"\n",
    "                'Use \"independent\" as the multi_output_strategy.'\n",
    "            )\n",
    "        self.multi_output_strategy = {\n",
    "            None: SingleOutputStrategy,\n",
    "            \"independent\": IndependentStrategy,\n",
    "            \"split_both\": SplitBothStrategy,\n",
    "            \"split_branch\": SplitBranchStrategy,\n",
    "            \"split_trunk\": SplitTrunkStrategy,\n",
    "        }[multi_output_strategy](self)\n",
    "\n",
    "\n",
    "        # Build the branch and trunk networks\n",
    "        # Use the selected multi-output strategy to build the branch and trunk networks\n",
    "        # The multi_output_strategy.build() method is expected to return two network components,\n",
    "        # which will be assigned to self.branch and self.trunk\n",
    "        self.branch, self.trunk = self.multi_output_strategy.build(\n",
    "            layer_sizes_branch, layer_sizes_trunk\n",
    "        )\n",
    "        if isinstance(self.branch, list):\n",
    "            self.branch = torch.nn.ModuleList(self.branch)\n",
    "        if isinstance(self.trunk, list):\n",
    "            self.trunk = torch.nn.ModuleList(self.trunk)\n",
    "        \n",
    "        # TODO: Initialize learnable parameters for output bias\n",
    "        # self.b should be a list of learnable parameters (torch.nn.Parameter) for each output\n",
    "        # Initialize these parameters with zeros using torch.nn.Parameter(torch.tensor(0.0))\n",
    "        self.b = torch.nn.ParameterList(\n",
    "            ...\n",
    "        )\n",
    "\n",
    "    def build_branch_net(self, layer_sizes_branch):\n",
    "        # Implement the branch network construction\n",
    "        # Check if layer_sizes_branch[1] is a callable function (user-defined network)\n",
    "        # If it is, return it directly. Otherwise, create a fully connected network (FNN)\n",
    "        # using the provided layer_sizes_branch and activation function.\n",
    "        # User-defined network: If the second element of layer_sizes_branch is a callable, return it\n",
    "        if callable(layer_sizes_branch[1]):\n",
    "            return layer_sizes_branch[1]\n",
    "            \n",
    "        # TODO: Return fully connected network: Create an FNN with specified layer sizes and activation function\n",
    "        return FNN(...)\n",
    "\n",
    "    def build_trunk_net(self, layer_sizes_trunk):\n",
    "        # TODO: Implement the trunk network construction\n",
    "        # Similar to the branch network, create a fully connected network (FNN)\n",
    "        # using the provided layer_sizes_trunk and activation function.\n",
    "        return FNN(...)\n",
    "\n",
    "    def merge_branch_trunk(self, x_func, x_loc, index):\n",
    "        # Merging of branch and trunk outputs\n",
    "        # Use torch.einsum with the expression \"bi,bi->b\" to perform element-wise\n",
    "        # multiplication of x_func and x_loc, followed by a summation over the last dimension.\n",
    "        # The result should be reshaped using torch.unsqueeze to add a new dimension.\n",
    "        # Finally, add the output bias self.b[index] to the result.\n",
    "        y = torch.einsum(\"bi,bi->b\", x_func, x_loc)\n",
    "        y = torch.unsqueeze(y, dim=1)\n",
    "        y += self.b[index]\n",
    "        return y\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_func = inputs[0]\n",
    "        x_loc = inputs[1]\n",
    "        \n",
    "        # TODO: Use the multi-output strategy to process the inputs\n",
    "        # Hint: Call self.multi_output_strategy.call() with x_func and x_loc.\n",
    "        x = ...\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def concatenate_outputs(ys):\n",
    "        return torch.concat(ys, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4651d-b08c-4508-9c83-15e9f20bf2f4",
   "metadata": {},
   "source": [
    "### Training with DeepONet in Darcy flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706eb4a8-8688-4d82-9974-4eabdb1ec12d",
   "metadata": {},
   "source": [
    "Having trained and tested the FNO model, you will now use the same small Darcy-Flow dataset with the package \"deepxde\" to train a Tensorized DeepONet model.\n",
    "\n",
    "*There is no code to fill in for this part, just run the code block by block in order.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce4cd3-9fdc-45a4-813c-495290d54488",
   "metadata": {},
   "source": [
    "**Loading and extracting the Darcy Flow small dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fa49f-ae3f-4a51-878e-cc47a0e85a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(\"data/darcy_train_16.pt\")\n",
    "test_data = torch.load(\"data/darcy_test_16.pt\")\n",
    "\n",
    "x_train = train_data['x'].float()\n",
    "y_train = train_data['y'].float()\n",
    "\n",
    "x_test = test_data['x'].float()\n",
    "y_test = test_data['y'].float()\n",
    "\n",
    "data = dde.data.Triple(X_train=x_train, y_train=y_train, X_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed1a34-0b7b-4d65-a099-254a5a09cf77",
   "metadata": {},
   "source": [
    "**Configure the DeepONet model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c4525-5cd2-4db4-9b76-489340ef6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a network\n",
    "m = 16\n",
    "dim_x = 16\n",
    "net = DeepONet(\n",
    "    [m, 16, 16, 16],\n",
    "    [dim_x, 16, 16, 16],\n",
    "    \"relu\",\n",
    "    \"Glorot normal\",\n",
    "    num_outputs=16,\n",
    "    multi_output_strategy=\"independent\",\n",
    ")\n",
    "\n",
    "# Define a Model\n",
    "model = dde.Model(data, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a70397-c141-4c02-ad3f-06083c6595ec",
   "metadata": {},
   "source": [
    "Compile and train the model using the Adam Optimizer with a learning rate of 0.001 (Execution time â‰ˆ 3min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb13cd-5349-44f6-a2b5-926b61208843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", lr=0.001)\n",
    "losshistory, train_state = model.train(iterations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5ee91-3d7b-4cd2-b918-311718d6b089",
   "metadata": {},
   "source": [
    "Plot the prediction and compare with the ground-truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of predictions\n",
    "test_samples = test_loaders[16].dataset\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "for index in range(3):\n",
    "    data = test_samples[index]\n",
    "    data = data_processor.preprocess(data, batched=False)\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    out = model.predict(x.detach().numpy())\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
    "    ax.imshow(x[0], cmap='gray')\n",
    "    if index == 0:\n",
    "        ax.set_title('Input x')\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
    "    ax.imshow(y.squeeze())\n",
    "    if index == 0:\n",
    "        ax.set_title('Ground-truth y')\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 3)\n",
    "    ax.imshow(out.squeeze())\n",
    "    if index == 0:\n",
    "        ax.set_title('Model prediction')\n",
    "\n",
    "fig.suptitle('Inputs, Ground-truth, and Model Prediction')\n",
    "plt.tight_layout()\n",
    "plt.savefig('neural_ops_output.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
